{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramNorm(nn.Module):\n",
    "    \"\"\"A `torch.nn.Module` that applies 2D batch normalization over spectrogram\n",
    "    per electrode channel per band. Inputs must be of shape\n",
    "    (T, N, num_bands, electrode_channels, frequency_bins).\n",
    "\n",
    "    With left and right bands and 16 electrode channels per band, spectrograms\n",
    "    corresponding to each of the 2 * 16 = 32 channels are normalized\n",
    "    independently using `nn.BatchNorm2d` such that stats are computed\n",
    "    over (N, freq, time) slices.\n",
    "\n",
    "    Args:\n",
    "        channels (int): Total number of electrode channels across bands\n",
    "            such that the normalization statistics are calculated per channel.\n",
    "            Should be equal to num_bands * electrode_chanels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        T, N, bands, C, freq = inputs.shape  # (T, N, bands=1, C=16, freq)\n",
    "        assert self.channels == bands * C\n",
    "\n",
    "        x = inputs.movedim(0, -1)  # (N, bands=1, C=8, freq, T)\n",
    "        x = x.reshape(N, bands * C, freq, T)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.reshape(N, bands, C, freq, T)\n",
    "        return x.movedim(-1, 0)  # (T, N, bands=1, C=8, freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationInvariantMLP(nn.Module):\n",
    "    \"\"\"A `torch.nn.Module` that takes an input tensor of shape\n",
    "    (T, N, electrode_channels, ...) corresponding to a single band, applies\n",
    "    an MLP after shifting/rotating the electrodes for each positional offset\n",
    "    in ``offsets``, and pools over all the outputs.\n",
    "\n",
    "    Returns a tensor of shape (T, N, mlp_features[-1]).\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features to the MLP. For an input of\n",
    "            shape (T, N, C, ...), this should be equal to C * ... (that is,\n",
    "            the flattened size from the channel dim onwards).\n",
    "        mlp_features (list): List of integers denoting the number of\n",
    "            out_features per layer in the MLP.\n",
    "        pooling (str): Whether to apply mean or max pooling over the outputs\n",
    "            of the MLP corresponding to each offset. (default: \"mean\")\n",
    "        offsets (list): List of positional offsets to shift/rotate the\n",
    "            electrode channels by. (default: ``(-1, 0, 1)``).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        mlp_features: Sequence[int],\n",
    "        pooling: str = \"mean\",\n",
    "        offsets: Sequence[int] = (-1, 0, 1),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(mlp_features) > 0\n",
    "        mlp: list[nn.Module] = []\n",
    "        for out_features in mlp_features:\n",
    "            mlp.extend(\n",
    "                [\n",
    "                    nn.Linear(in_features, out_features),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "            )\n",
    "            in_features = out_features\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "\n",
    "        assert pooling in {\"max\", \"mean\"}, f\"Unsupported pooling: {pooling}\"\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.offsets = offsets if len(offsets) > 0 else (0,)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x = inputs  # (T, N, C, ...)\n",
    "\n",
    "        # Create a new dim for band rotation augmentation with each entry\n",
    "        # corresponding to the original tensor with its electrode channels\n",
    "        # shifted by one of ``offsets``:\n",
    "        # (T, N, C, ...) -> (T, N, rotation, C, ...)\n",
    "        x = torch.stack([x.roll(offset, dims=2) for offset in self.offsets], dim=2)\n",
    "\n",
    "        # Flatten features and pass through MLP:\n",
    "        # (T, N, rotation, C, ...) -> (T, N, rotation, mlp_features[-1])\n",
    "        x = self.mlp(x.flatten(start_dim=3))\n",
    "\n",
    "        # Pool over rotations:\n",
    "        # (T, N, rotation, mlp_features[-1]) -> (T, N, mlp_features[-1])\n",
    "        if self.pooling == \"max\":\n",
    "            return x.max(dim=2).values\n",
    "        else:\n",
    "            return x.mean(dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDSConv2dBlock(nn.Module):\n",
    "    \"\"\"A 2D temporal convolution block as per \"Sequence-to-Sequence Speech\n",
    "    Recognition with Time-Depth Separable Convolutions, Hannun et al\"\n",
    "    (https://arxiv.org/abs/1904.02619).\n",
    "\n",
    "    Args:\n",
    "        channels (int): Number of input and output channels. For an input of\n",
    "            shape (T, N, num_features), the invariant we want is\n",
    "            channels * width = num_features.\n",
    "        width (int): Input width. For an input of shape (T, N, num_features),\n",
    "            the invariant we want is channels * width = num_features.\n",
    "        kernel_width (int): The kernel size of the temporal convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, width: int, kernel_width: int) -> None:\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "\n",
    "        self.conv2d = nn.Conv2d(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=(1, kernel_width),\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_norm = nn.LayerNorm(channels * width)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        T_in, N, C = inputs.shape  # TNC\n",
    "\n",
    "        # TNC -> NCT -> NcwT\n",
    "        x = inputs.movedim(0, -1).reshape(N, self.channels, self.width, T_in)\n",
    "        x = self.conv2d(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.reshape(N, C, -1).movedim(-1, 0)  # NcwT -> NCT -> TNC\n",
    "\n",
    "        # Skip connection after downsampling\n",
    "        T_out = x.shape[0]\n",
    "        x = x + inputs[-T_out:]\n",
    "\n",
    "        # Layer norm over C\n",
    "        return self.layer_norm(x)  # TNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDSFullyConnectedBlock(nn.Module):\n",
    "    \"\"\"A fully connected block as per \"Sequence-to-Sequence Speech\n",
    "    Recognition with Time-Depth Separable Convolutions, Hannun et al\"\n",
    "    (https://arxiv.org/abs/1904.02619).\n",
    "\n",
    "    Args:\n",
    "        num_features (int): ``num_features`` for an input of shape\n",
    "            (T, N, num_features).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, num_features),\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(num_features)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x = inputs  # TNC\n",
    "        x = self.fc_block(x)\n",
    "        x = x + inputs\n",
    "        return self.layer_norm(x)  # TNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDSConvEncoder(nn.Module):\n",
    "    \"\"\"A time depth-separable convolutional encoder composing a sequence\n",
    "    of `TDSConv2dBlock` and `TDSFullyConnectedBlock` as per\n",
    "    \"Sequence-to-Sequence Speech Recognition with Time-Depth Separable\n",
    "    Convolutions, Hannun et al\" (https://arxiv.org/abs/1904.02619).\n",
    "\n",
    "    Args:\n",
    "        num_features (int): ``num_features`` for an input of shape\n",
    "            (T, N, num_features).\n",
    "        block_channels (list): A list of integers indicating the number\n",
    "            of channels per `TDSConv2dBlock`.\n",
    "        kernel_width (int): The kernel size of the temporal convolutions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        block_channels: Sequence[int] = (24, 24, 24, 24),\n",
    "        kernel_width: int = 32,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(block_channels) > 0\n",
    "        tds_conv_blocks: list[nn.Module] = []\n",
    "        for channels in block_channels:\n",
    "            assert (\n",
    "                num_features % channels == 0\n",
    "            ), \"block_channels must evenly divide num_features\"\n",
    "            tds_conv_blocks.extend(\n",
    "                [\n",
    "                    TDSConv2dBlock(channels, num_features // channels, kernel_width),\n",
    "                    TDSFullyConnectedBlock(num_features),\n",
    "                ]\n",
    "            )\n",
    "        self.tds_conv_blocks = nn.Sequential(*tds_conv_blocks)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return self.tds_conv_blocks(inputs)  # (T, N, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOTA-4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
